{
    "model_name": "meta-llama/Llama-3.1-8B-Instruct",

    "num_tokens": 500000000,
    "buffer_tokens": 250000,
    "architectures": ["batch_top_k"],
    "dictionary_widths": [131072],
    "target_l0s": [32, 64, 128, 256],
    "layers": [3],
    "learning_rates": [2e-4],
    "llm_batch_size": 16,
    "llm_context_length": 1024,
    "sae_batch_size": 2048,
    "dtype": "bfloat16",

    "use_wandb": true,
    "wandb_project": "sae-sweep",
    "wandb_name_prefix": "2_l03",
    "save_dir": "/workspace/sae/llama-3-8b-instruct/runs/2_l03",
    "save_checkpoints": true,
    "hf_repo_id": null,

    "device": "cuda",
    "activation_buffer_internal_device": "cuda",
    "random_seeds": [0],
    "eval_num_inputs": 200,
    "log_steps": 100,
    "chat_data_fraction": 0.35,
    "pretrain_data_fraction": 0.64,
    "misaligned_data_fraction": 0.01,
    "chat_data_remove_system_prompt_p": 0.80
}